{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pandas_profiling\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-02T12:36:24.809930Z","iopub.execute_input":"2022-02-02T12:36:24.810652Z","iopub.status.idle":"2022-02-02T12:36:24.814697Z","shell.execute_reply.started":"2022-02-02T12:36:24.810615Z","shell.execute_reply":"2022-02-02T12:36:24.813867Z"},"trusted":true},"execution_count":213,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/daconstudy/train.csv')\ntest_df = pd.read_csv('../input/daconstudy/test.csv')\n\nsub_id = test_df['id']\n\ntrain_df = train_df.drop('id', axis = 1)\ntest_df = test_df.drop('id', axis = 1)\n# 중복 데이터 제거\ntrain_df = train_df.drop_duplicates()   \n# 데이터의 분포 확인\nprofile = train_df.profile_report()\n\n# profile","metadata":{"execution":{"iopub.status.busy":"2022-02-02T12:36:25.126000Z","iopub.execute_input":"2022-02-02T12:36:25.126458Z","iopub.status.idle":"2022-02-02T12:36:25.153424Z","shell.execute_reply.started":"2022-02-02T12:36:25.126421Z","shell.execute_reply":"2022-02-02T12:36:25.152759Z"},"trusted":true},"execution_count":214,"outputs":[]},{"cell_type":"markdown","source":"# 알 수 있는 것들\n- Gr Liv Area, Garage Area, 1st Flr SF, target  정규화\n- Data 범주화\n- Garage Yr Blt 2207 삭제","metadata":{}},{"cell_type":"code","source":"train_df = train_df.drop(train_df[train_df['Garage Yr Blt'] == 2207].index)\nprint('train_df Shape :', train_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T12:36:27.030848Z","iopub.execute_input":"2022-02-02T12:36:27.031809Z","iopub.status.idle":"2022-02-02T12:36:27.039190Z","shell.execute_reply.started":"2022-02-02T12:36:27.031763Z","shell.execute_reply":"2022-02-02T12:36:27.038264Z"},"trusted":true},"execution_count":215,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-02T12:36:27.463789Z","iopub.execute_input":"2022-02-02T12:36:27.464403Z","iopub.status.idle":"2022-02-02T12:36:27.476380Z","shell.execute_reply.started":"2022-02-02T12:36:27.464361Z","shell.execute_reply":"2022-02-02T12:36:27.475549Z"},"trusted":true},"execution_count":216,"outputs":[]},{"cell_type":"code","source":"def preprocess_data(data, features):\n    category = {'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5}\n    \n    # log\n    for feature in features:\n        data[feature] = np.log1p(data[feature])\n    \n    # Categorical\n    data['Exter Qual'] = data['Exter Qual'].map(category)\n    data['Kitchen Qual'] = data['Kitchen Qual'].map(category)\n    data['Bsmt Qual'] = data['Bsmt Qual'].map(category)\n    \n    # Create New Perspective \n    data['Remodeling'] = data['Year Remod/Add'] - data['Year Built']\n    data['2nd SF'] = data['Gr Liv Area'] - data['1st Flr SF']\n    data['2nd flr'] = data['2nd SF'].apply(lambda x : 1 if x > 0 else 0)\n    data['Total_Qual'] = data['Exter Qual'] + data['Kitchen Qual'] + data['Overall Qual'] + data['Bsmt Qual']\n    data['Total_Area'] = data['Gr Liv Area'] + data['Garage Area'] + data['Total Bsmt SF']\n    \n    # 동화님 아이디어 참고\n    data['Car Area'] = data['Garage Area'] / data['Garage Cars']\n    data['Garage InOut'] = data.apply(lambda x : 1 if x['Gr Liv Area'] != x['1st Flr SF'] else 0, axis=1)    \n    \n    return data\n\nfeatures_train = ['Total Bsmt SF', '1st Flr SF', 'Gr Liv Area', 'Garage Area', 'target']\nfeatures_test = ['Total Bsmt SF', '1st Flr SF', 'Gr Liv Area', 'Garage Area']\n\ntrain_df = preprocess_data(train_df, features_train)\ntest_df = preprocess_data(test_df, features_test)\n\ntrain_label = train_df['target']\ntrain_df = train_df.drop('target', axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T12:36:28.253602Z","iopub.execute_input":"2022-02-02T12:36:28.254439Z","iopub.status.idle":"2022-02-02T12:36:28.351833Z","shell.execute_reply.started":"2022-02-02T12:36:28.254393Z","shell.execute_reply":"2022-02-02T12:36:28.351168Z"},"trusted":true},"execution_count":217,"outputs":[]},{"cell_type":"code","source":"# Metric\ndef NMAE(true, pred):\n    mae = np.mean(np.abs(true-pred))\n    score = mae / np.mean(np.abs(true))\n    return score","metadata":{"execution":{"iopub.status.busy":"2022-02-02T12:36:30.126614Z","iopub.execute_input":"2022-02-02T12:36:30.127078Z","iopub.status.idle":"2022-02-02T12:36:30.131566Z","shell.execute_reply.started":"2022-02-02T12:36:30.127041Z","shell.execute_reply":"2022-02-02T12:36:30.130903Z"},"trusted":true},"execution_count":218,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\nfrom catboost import CatBoostRegressor, Pool\nfrom ngboost import NGBRegressor\nfrom sklearn.metrics import make_scorer\nfrom sklearn.model_selection import KFold","metadata":{"execution":{"iopub.status.busy":"2022-02-02T12:19:59.865178Z","iopub.execute_input":"2022-02-02T12:19:59.865742Z","iopub.status.idle":"2022-02-02T12:19:59.871749Z","shell.execute_reply.started":"2022-02-02T12:19:59.865700Z","shell.execute_reply":"2022-02-02T12:19:59.870895Z"},"trusted":true},"execution_count":189,"outputs":[]},{"cell_type":"code","source":"nmae_score = make_scorer(NMAE, greater_is_better=False)\n\nkf = KFold(n_splits = 10, random_state = 42, shuffle = True)\n\n# LinearRegression\nlr_pred = np.zeros(test_df.shape[0])\n\nlr_val = []\nfor n, (tr_idx, val_idx) in enumerate(kf.split(train_df, train_label)) :\n    print(f'{n+1} Fold Training')\n    train_x, train_y = train_df.iloc[tr_idx], train_label.iloc[tr_idx]\n    valid_x, valid_y = train_df.iloc[val_idx], train_label.iloc[val_idx]\n    \n    lr = LinearRegression()\n    lr.fit(train_x,train_y)\n    \n    val_pred = np.expm1(lr.predict(valid_x))\n    val_NMAE = NMAE(np.expm1(valid_y), val_pred)\n    \n    lr_val.append(val_NMAE)\n    print(f'{n+1} FOLD NMAE = {val_NMAE}')\n    \n    target_data = Pool(data = test_df, label = None)\n    fold_pred = lr.predict(test_df) / 10\n    \n    lr_pred += fold_pred\n\nprint(f'10FOLD Mean of NMAE = {np.mean(lr_val)} & std = {np.std(lr_val)}')","metadata":{"execution":{"iopub.status.busy":"2022-02-02T12:20:06.786407Z","iopub.execute_input":"2022-02-02T12:20:06.786923Z","iopub.status.idle":"2022-02-02T12:20:07.097495Z","shell.execute_reply.started":"2022-02-02T12:20:06.786880Z","shell.execute_reply":"2022-02-02T12:20:07.096655Z"},"trusted":true},"execution_count":190,"outputs":[]},{"cell_type":"code","source":"# Ridge\nrg_pred = np.zeros(test_df.shape[0])\n\nrg_val = []\nfor n, (tr_idx, val_idx) in enumerate(kf.split(train_df, train_label)) :\n    print(f'{n+1} Fold Training')\n    train_x, train_y = train_df.iloc[tr_idx], train_label.iloc[tr_idx]\n    valid_x, valid_y = train_df.iloc[val_idx], train_label.iloc[val_idx]\n    \n    rg = Ridge()\n    rg.fit(train_x,train_y)\n    \n    val_pred = np.expm1(rg.predict(valid_x))\n    val_NMAE = NMAE(np.expm1(valid_y), val_pred)\n    \n    rg_val.append(val_NMAE)\n    print(f'{n+1} FOLD NMAE = {val_NMAE}')\n    \n    target_data = Pool(data = test_df, label = None)\n    fold_pred = rg.predict(test_df) / 10\n    \n    rg_pred += fold_pred\n\nprint(f'10FOLD Mean of NMAE = {np.mean(rg_val)} & std = {np.std(rg_val)}')","metadata":{"execution":{"iopub.status.busy":"2022-02-02T12:29:10.161164Z","iopub.execute_input":"2022-02-02T12:29:10.161966Z","iopub.status.idle":"2022-02-02T12:29:10.329255Z","shell.execute_reply.started":"2022-02-02T12:29:10.161902Z","shell.execute_reply":"2022-02-02T12:29:10.328459Z"},"trusted":true},"execution_count":202,"outputs":[]},{"cell_type":"code","source":"# Lasso\nlasso_pred = np.zeros(test_df.shape[0])\n\nlasso_val = []\nfor n, (tr_idx, val_idx) in enumerate(kf.split(train_df, train_label)) :\n    print(f'{n+1} Fold Training')\n    train_x, train_y = train_df.iloc[tr_idx], train_label.iloc[tr_idx]\n    valid_x, valid_y = train_df.iloc[val_idx], train_label.iloc[val_idx]\n    \n    ls = Lasso()\n    ls.fit(train_x,train_y)\n    \n    val_pred = np.expm1(ls.predict(valid_x))\n    val_NMAE = NMAE(np.expm1(valid_y), val_pred)\n    \n    lasso_val.append(val_NMAE)\n    print(f'{n+1} FOLD NMAE = {val_NMAE}')\n    \n    target_data = Pool(data = test_df, label = None)\n    fold_pred = ls.predict(test_df) / 10\n    \n    lasso_pred += fold_pred\n\nprint(f'10FOLD Mean of NMAE = {np.mean(lasso_val)} & std = {np.std(lasso_val)}')","metadata":{"execution":{"iopub.status.busy":"2022-02-02T12:29:12.359889Z","iopub.execute_input":"2022-02-02T12:29:12.360408Z","iopub.status.idle":"2022-02-02T12:29:12.579159Z","shell.execute_reply.started":"2022-02-02T12:29:12.360367Z","shell.execute_reply":"2022-02-02T12:29:12.578367Z"},"trusted":true},"execution_count":203,"outputs":[]},{"cell_type":"code","source":"# ElasticNet\nels_pred = np.zeros(test_df.shape[0])\n\nels_val = []\nfor n, (tr_idx, val_idx) in enumerate(kf.split(train_df, train_label)) :\n    print(f'{n+1} Fold Training')\n    train_x, train_y = train_df.iloc[tr_idx], train_label.iloc[tr_idx]\n    valid_x, valid_y = train_df.iloc[val_idx], train_label.iloc[val_idx]\n    \n    els = ElasticNet()\n    els.fit(train_x,train_y)\n    \n    val_pred = np.expm1(els.predict(valid_x))\n    val_NMAE = NMAE(np.expm1(valid_y), val_pred)\n    \n    els_val.append(val_NMAE)\n    print(f'{n+1} FOLD NMAE = {val_NMAE}')\n    \n    target_data = Pool(data = test_df, label = None)\n    fold_pred = els.predict(test_df) / 10\n    \n    els_pred += fold_pred\n\nprint(f'10FOLD Mean of NMAE = {np.mean(els_val)} & std = {np.std(els_val)}')","metadata":{"execution":{"iopub.status.busy":"2022-02-02T12:29:22.737812Z","iopub.execute_input":"2022-02-02T12:29:22.738371Z","iopub.status.idle":"2022-02-02T12:29:22.892484Z","shell.execute_reply.started":"2022-02-02T12:29:22.738331Z","shell.execute_reply":"2022-02-02T12:29:22.891712Z"},"trusted":true},"execution_count":204,"outputs":[]},{"cell_type":"code","source":"# GBR\ngbr_pred = np.zeros(test_df.shape[0])\n\ngbr_val = []\nfor n, (tr_idx, val_idx) in enumerate(kf.split(train_df, train_label)) :\n    print(f'{n+1} Fold Training')\n    train_x, train_y = train_df.iloc[tr_idx], train_label.iloc[tr_idx]\n    valid_x, valid_y = train_df.iloc[val_idx], train_label.iloc[val_idx]\n    \n    gbr = GradientBoostingRegressor(min_samples_leaf=15)\n    gbr.fit(train_x,train_y)\n    \n    val_pred = np.expm1(gbr.predict(valid_x))\n    val_NMAE = NMAE(np.expm1(valid_y), val_pred)\n    \n    gbr_val.append(val_NMAE)\n    print(f'{n+1} FOLD NMAE = {val_NMAE}')\n    \n    target_data = Pool(data = test_df, label = None)\n    fold_pred = gbr.predict(test_df) / 10\n    \n    gbr_pred += fold_pred\n\nprint(f'10FOLD Mean of NMAE = {np.mean(gbr_val)} & std = {np.std(gbr_val)}')","metadata":{"execution":{"iopub.status.busy":"2022-02-02T12:20:24.487129Z","iopub.execute_input":"2022-02-02T12:20:24.487861Z","iopub.status.idle":"2022-02-02T12:20:27.595187Z","shell.execute_reply.started":"2022-02-02T12:20:24.487823Z","shell.execute_reply":"2022-02-02T12:20:27.594424Z"},"trusted":true},"execution_count":191,"outputs":[]},{"cell_type":"code","source":"# RF\nrf_pred = np.zeros(test_df.shape[0])\nrf_val = []\n\nfor n, (tr_idx, val_idx) in enumerate(kf.split(train_df, train_label)) :\n    print(f'{n+1} Fold Training')\n    train_x, train_y = train_df.iloc[tr_idx], train_label.iloc[tr_idx]\n    valid_x, valid_y = train_df.iloc[val_idx], train_label.iloc[val_idx]\n    \n    rf = RandomForestRegressor(random_state= 32, criterion= 'mae')\n    rf.fit(train_x,train_y)\n    \n    val_pred = np.expm1(rf.predict(valid_x))\n    val_NMAE = NMAE(np.expm1(valid_y), val_pred)\n    \n    rf_val.append(val_NMAE)\n    print(f'{n+1} FOLD NMAE = {val_NMAE}')\n    \n    target_data = Pool(data = test_df, label = None)\n    fold_pred = rf.predict(test_df) / 10\n    \n    rf_pred += fold_pred\n\nprint(f'10FOLD Mean of NMAE = {np.mean(rf_val)} & std = {np.std(rf_val)}')\n# 10FOLD Mean of NMAE = 0.11824903167369834 & std = 0.006347554553427555","metadata":{"execution":{"iopub.status.busy":"2022-02-02T12:22:00.112981Z","iopub.execute_input":"2022-02-02T12:22:00.113840Z","iopub.status.idle":"2022-02-02T12:23:10.507641Z","shell.execute_reply.started":"2022-02-02T12:22:00.113791Z","shell.execute_reply":"2022-02-02T12:23:10.506918Z"},"trusted":true},"execution_count":195,"outputs":[]},{"cell_type":"code","source":"# NGBRegressor\nngb_pred = np.zeros(test_df.shape[0])\n\nngb_val = []\nfor n, (tr_idx, val_idx) in enumerate(kf.split(train_df, train_label)) :\n    print(f'{n+1} Fold Training')\n    train_x, train_y = train_df.iloc[tr_idx], train_label.iloc[tr_idx]\n    valid_x, valid_y = train_df.iloc[val_idx], train_label.iloc[val_idx]\n    \n    ngb = NGBRegressor(random_state = 42, n_estimators = 1000, verbose = 0, learning_rate = 0.03)\n    ngb.fit(train_x, train_y, valid_x, valid_y, early_stopping_rounds = 300)\n    \n    val_pred = np.expm1(ngb.predict(valid_x))\n    val_NMAE = NMAE(np.expm1(valid_y), val_pred)\n    \n    ngb_val.append(val_NMAE)\n    print(f'{n+1} FOLD NMAE = {val_NMAE}')\n    \n    target_data = Pool(data = test_df, label = None)\n    fold_pred = rf.predict(test_df) / 10\n    \n    ngb_pred += fold_pred\n\nprint(f'10FOLD Mean of NMAE = {np.mean(ngb_val)} & std = {np.std(ngb_val)}')\n# 0.09461596073922843 & std = 0.009333805300220727","metadata":{"execution":{"iopub.status.busy":"2022-02-02T12:23:57.862079Z","iopub.execute_input":"2022-02-02T12:23:57.862775Z","iopub.status.idle":"2022-02-02T12:24:58.429889Z","shell.execute_reply.started":"2022-02-02T12:23:57.862728Z","shell.execute_reply":"2022-02-02T12:24:58.429015Z"},"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import BayesianRidge\n\nby_pred = np.zeros(test_df.shape[0])\nby_val = []\n\nfor n, (tr_idx, val_idx) in enumerate(kf.split(train_df, train_label)) :\n    print(f'{n + 1} FOLD Training.....')\n    train_x, train_y = train_df.iloc[tr_idx], train_label.iloc[tr_idx]\n    valid_x, valid_y = train_df.iloc[val_idx], train_label.iloc[val_idx]\n    \n    by = BayesianRidge()\n    by.fit(train_x, train_y)\n    \n    val_pred = np.expm1(by.predict(valid_x))\n    val_nmae = NMAE(np.expm1(valid_y), val_pred)\n    by_val.append(val_nmae)\n    print(f'{n + 1} FOLD NMAE = {val_nmae}\\n')\n    \n    target_data = Pool(data = test_df, label = None)\n    fold_pred = cb.predict(test_df) / 10\n    by_pred += fold_pred\nprint(f'10FOLD Mean of NMAE = {np.mean(by_val)} & std = {np.std(by_val)}')","metadata":{"execution":{"iopub.status.busy":"2022-02-02T12:29:35.002524Z","iopub.execute_input":"2022-02-02T12:29:35.002806Z","iopub.status.idle":"2022-02-02T12:29:35.324248Z","shell.execute_reply.started":"2022-02-02T12:29:35.002774Z","shell.execute_reply":"2022-02-02T12:29:35.323489Z"},"trusted":true},"execution_count":205,"outputs":[]},{"cell_type":"code","source":"# Catboost\ncb_pred = np.zeros(test_df.shape[0])\ncb_val = []\nfor n, (tr_idx, val_idx) in enumerate(kf.split(train_df, train_label)) :\n    print(f'{n + 1} FOLD Training.....')\n    train_x, train_y = train_df.iloc[tr_idx], train_label.iloc[tr_idx]\n    valid_x, valid_y = train_df.iloc[val_idx], train_label.iloc[val_idx]\n    \n    tr_data = Pool(data = train_x, label = train_y)\n    val_data = Pool(data = valid_x, label = valid_y)\n    \n    cb = CatBoostRegressor(depth = 4, random_state = 42, loss_function = 'MAE', n_estimators = 3000, learning_rate = 0.03, verbose = 0)\n    cb.fit(tr_data, eval_set = val_data, early_stopping_rounds = 750, verbose = 1000)\n    \n    val_pred = np.expm1(cb.predict(valid_x))\n    val_nmae = NMAE(np.expm1(valid_y), val_pred)\n    cb_val.append(val_nmae)\n    print(f'{n + 1} FOLD NMAE = {val_nmae}\\n')\n    \n    target_data = Pool(data = test_df, label = None)\n    fold_pred = cb.predict(test_df) / 10\n    cb_pred += fold_pred\nprint(f'10FOLD Mean of NMAE = {np.mean(cb_val)} & std = {np.std(cb_val)}')\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-02T12:25:21.262438Z","iopub.execute_input":"2022-02-02T12:25:21.262694Z","iopub.status.idle":"2022-02-02T12:25:41.994621Z","shell.execute_reply.started":"2022-02-02T12:25:21.262663Z","shell.execute_reply":"2022-02-02T12:25:41.993788Z"},"trusted":true},"execution_count":199,"outputs":[]},{"cell_type":"code","source":"target = np.expm1((gbr_pred + rf_pred + ngb_pred + cb_pred) / 4)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T12:25:49.707162Z","iopub.execute_input":"2022-02-02T12:25:49.707579Z","iopub.status.idle":"2022-02-02T12:25:49.713020Z","shell.execute_reply.started":"2022-02-02T12:25:49.707543Z","shell.execute_reply":"2022-02-02T12:25:49.712198Z"},"trusted":true},"execution_count":200,"outputs":[]},{"cell_type":"code","source":"# 검증 성능 확인하기\nval_list = [lr_val, rg_val, ls_val, el_val,by_val, gbr_val, rf_val, ngb_val, cb_val]\nfor val in val_list :\n    print(\"{:.8f}\".format(np.mean(val))) ","metadata":{"execution":{"iopub.status.busy":"2022-02-02T12:30:00.743924Z","iopub.execute_input":"2022-02-02T12:30:00.744677Z","iopub.status.idle":"2022-02-02T12:30:00.752726Z","shell.execute_reply.started":"2022-02-02T12:30:00.744639Z","shell.execute_reply":"2022-02-02T12:30:00.751532Z"},"trusted":true},"execution_count":206,"outputs":[]},{"cell_type":"code","source":"sub_park = pd.DataFrame({\n    'id' : sub_id,\n    'target': target\n})\n\nsub_park.to_csv('sz1.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T12:25:53.652507Z","iopub.execute_input":"2022-02-02T12:25:53.652770Z","iopub.status.idle":"2022-02-02T12:25:53.665574Z","shell.execute_reply.started":"2022-02-02T12:25:53.652738Z","shell.execute_reply":"2022-02-02T12:25:53.664784Z"},"trusted":true},"execution_count":201,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\n","metadata":{"execution":{"iopub.status.busy":"2022-02-02T12:31:29.772493Z","iopub.execute_input":"2022-02-02T12:31:29.773333Z","iopub.status.idle":"2022-02-02T12:31:29.777722Z","shell.execute_reply.started":"2022-02-02T12:31:29.773270Z","shell.execute_reply":"2022-02-02T12:31:29.776899Z"},"trusted":true},"execution_count":208,"outputs":[]},{"cell_type":"code","source":"# Catboost\nxgb_pred = np.zeros(test_df.shape[0])\nxgb_val = []\nfor n, (tr_idx, val_idx) in enumerate(kf.split(train_df, train_label)) :\n    print(f'{n + 1} FOLD Training')\n    train_x, train_y = train_df.iloc[tr_idx], train_label.iloc[tr_idx]\n    valid_x, valid_y = train_df.iloc[val_idx], train_label.iloc[val_idx]\n    \n    xgb = XGBRegressor(depth = 4, random_state = 42, learning_rate = 0.03)\n    xgb.fit(train_x, train_y)\n    \n    val_pred = np.expm1(xgb.predict(valid_x))\n    val_nmae = NMAE(np.expm1(valid_y), val_pred)\n    xgb_val.append(val_nmae)\n    print(f'{n + 1} FOLD NMAE = {val_nmae}\\n')\n    \n    target_data = Pool(data = test_df, label = None)\n    fold_pred = xgb.predict(test_df) / 10\n    xgb_pred += fold_pred\n    \nprint(f'10FOLD Mean of NMAE = {np.mean(xgb_val)} & std = {np.std(xgb_val)}')","metadata":{"execution":{"iopub.status.busy":"2022-02-02T12:36:56.087822Z","iopub.execute_input":"2022-02-02T12:36:56.088538Z","iopub.status.idle":"2022-02-02T12:36:57.525818Z","shell.execute_reply.started":"2022-02-02T12:36:56.088500Z","shell.execute_reply":"2022-02-02T12:36:57.525188Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":219,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\nfrom catboost import CatBoostRegressor\nfrom ngboost import NGBRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom xgboost import XGBRegressor\n\ngbr = GradientBoostingRegressor()\nrf = RandomForestRegressor()\nngb = NGBRegressor()\ncb = CatBoostRegressor()\n\nestimators = [gbr, rf, ngb, cb]\n\nparams_gbr = {'n_estimators' : [100],\n             'learning_rate' : [0.01, 0.02, 0.05, 0.1],\n             'max_depth' : [1, 2, 3, 4],\n             'min_samples_leaf' : [5, 10, 15],\n             'min_samples_split' : [2, 5, 10]}\n\nparams_rf = {\n    'n_estimators': [100], \n    'max_leaf_nodes': list(range(2, 10, 2)), \n    'max_depth': list(range(6, 30, 3))\n}\n\nparams_ngb = {\n    'n_estimators': [100], \n    'learning_rate': [0.01, 0.02, 0.05, 0.3, 0.5, 0.7, 0.1]\n}\n\nparams_cb = {'depth': [ 6,8,10],\n             'learning_rate' : [0.01, 0.02, 0.05, 0.3, 0.5, 0.7, 0.1],\n             'iterations'    : [30, 50, 100]\n}\n\nparams = [params_gbr, params_rf, params_ngb, params_cb]","metadata":{"execution":{"iopub.status.busy":"2022-02-02T11:56:19.411184Z","iopub.execute_input":"2022-02-02T11:56:19.411446Z","iopub.status.idle":"2022-02-02T11:56:19.423853Z","shell.execute_reply.started":"2022-02-02T11:56:19.411412Z","shell.execute_reply":"2022-02-02T11:56:19.423078Z"},"trusted":true},"execution_count":176,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\ndef gridSearhCV(models, params):\n    best_models = []\n    for i in tqdm(range(0, len(models))):\n        model_grid = GridSearchCV(models[i], params[i], n_jobs = -1, cv = 10)\n        model_grid.fit(train_df, train_label)\n        best_models.append(model_grid.best_estimator_)\n    \n    return best_models\n\nbest_model_list = gridSearhCV(estimators, params)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T12:02:32.292223Z","iopub.execute_input":"2022-02-02T12:02:32.292491Z","iopub.status.idle":"2022-02-02T12:17:27.681859Z","shell.execute_reply.started":"2022-02-02T12:02:32.292462Z","shell.execute_reply":"2022-02-02T12:17:27.681149Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":178,"outputs":[]},{"cell_type":"code","source":"best_model_list","metadata":{"execution":{"iopub.status.busy":"2022-02-02T12:18:51.132724Z","iopub.execute_input":"2022-02-02T12:18:51.133013Z","iopub.status.idle":"2022-02-02T12:18:51.141174Z","shell.execute_reply.started":"2022-02-02T12:18:51.132981Z","shell.execute_reply":"2022-02-02T12:18:51.140280Z"},"trusted":true},"execution_count":182,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}